# Aris AI â€” Hybrid AI Assistant

<p align="center">
  <strong>A ChatGPT-like AI assistant with a split-architecture design</strong><br>
  Cloud orchestration + Local GPU inference = Cost-efficient, responsive AI
</p>

---

## ğŸ¯ Overview

**Aris AI** is a personal AI assistant built with a **hybrid architecture** that separates cloud orchestration from local GPU inference. This design maximizes stability, performance, and cost efficiency by leveraging:

- **Railway (Cloud)** â€” Lightweight API gateway, orchestration, and state management
- **Local GPU** â€” Quantized LLM inference on your hardware
- **Flutter** â€” Cross-platform mobile/desktop client

> ğŸš€ **Goal**: ChatGPT-like responsiveness without cloud GPU costs

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              ARIS AI SYSTEM                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚               â”‚  HTTPS  â”‚                   â”‚   HTTP  â”‚              â”‚ â”‚
â”‚   â”‚  Flutter App  â”‚ â—„â”€â”€â”€â”€â”€â–º â”‚  Railway Backend  â”‚ â—„â”€â”€â”€â”€â”€â–º â”‚  Local GPU   â”‚ â”‚
â”‚   â”‚  (Frontend)   â”‚         â”‚  (Orchestration)  â”‚         â”‚  (Inference) â”‚ â”‚
â”‚   â”‚               â”‚         â”‚                   â”‚         â”‚              â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚   â–º UI Rendering            â–º FastAPI Server               â–º Ollama Runtimeâ”‚
â”‚   â–º Voice Input            â–º Auth & Sessions              â–º Quantized LLMs â”‚
â”‚   â–º Notifications          â–º Prompt Routing               â–º GPU Accel.     â”‚
â”‚   â–º Biometric Auth         â–º Web Scraping                 â–º Streaming      â”‚
â”‚                            â–º Scheduled Jobs                                â”‚
â”‚                            â–º Memory Management                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Component Responsibilities

### 1ï¸âƒ£ Flutter Frontend

| Responsibility   | Description                                |
| ---------------- | ------------------------------------------ |
| UI Rendering     | ChatGPT-like conversational interface      |
| Voice Capture    | Audio recording with waveform animations   |
| Message Handling | Sending/receiving streamed responses       |
| Notifications    | Push notifications for scheduled updates   |
| Personal Space   | Secure vault with biometric authentication |
| Settings         | User preferences and configuration         |

**Tech Stack:**

- Flutter 3.10+ with Dart
- Riverpod (state management)
- Dio (HTTP client)
- Hive (local storage)
- Google Sign-In

### 2ï¸âƒ£ Railway Backend (Cloud)

| Responsibility        | Description                                |
| --------------------- | ------------------------------------------ |
| API Gateway           | HTTPS endpoints for frontend communication |
| Authentication        | User auth, session management, tokens      |
| Prompt Classification | Categorizing user intent                   |
| Routing Logic         | Deciding which inference source to use     |
| Web Scraping          | Lightweight content retrieval              |
| Scheduled Jobs        | Daily update triggers                      |
| State Management      | Conversation history, memory               |
| Personal Space ACL    | Access control for secure data             |

**What Railway MUST NOT do:**

- âŒ Run large language models
- âŒ Perform GPU-based inference
- âŒ Execute full-precision LLM operations
- âŒ Assume GPU/CUDA availability

> Railway operates as a **control plane**, not a compute engine.

### 3ï¸âƒ£ Local Inference Node (GPU)

| Responsibility | Description                         |
| -------------- | ----------------------------------- |
| LLM Execution  | Run quantized models (Q4 preferred) |
| Summarization  | Process retrieved content           |
| Reasoning      | Coding, math, explanations          |
| Streaming      | Token-by-token response delivery    |

**Hardware Profile:**

- Windows host
- NVIDIA GTX 1650 (4 GB VRAM)
- Ollama runtime with GPU acceleration

**Constraints:**

- âœ… One model loaded at a time
- âœ… Quantized models only (Q4_K_M recommended)
- âŒ No auth handling
- âŒ No scheduling logic
- âŒ No direct internet exposure

---

## ğŸ”„ Request Flows

### Normal Chat Flow

```mermaid
sequenceDiagram
    participant User
    participant Flutter
    participant Railway
    participant LocalGPU

    User->>Flutter: Send message
    Flutter->>Railway: POST /chat (HTTPS)
    Railway->>Railway: Classify prompt
    Railway->>Railway: Retrieve context (if needed)
    Railway->>LocalGPU: Forward to inference API
    LocalGPU->>LocalGPU: Generate response
    LocalGPU-->>Railway: Stream tokens
    Railway-->>Flutter: Stream response
    Flutter-->>User: Display message
```

### Scheduled Daily Updates Flow

```mermaid
sequenceDiagram
    participant Scheduler
    participant Railway
    participant LocalGPU
    participant User

    Note over Scheduler: Configured time reached
    Scheduler->>Railway: Trigger update task
    Railway->>Railway: Perform focused scraping
    Railway->>LocalGPU: Request summarization
    LocalGPU-->>Railway: Return summary
    Railway->>Railway: Store result
    Railway-->>User: Send notification
    User->>Railway: Open app
    Railway->>User: Create chat with context
```

---

## ğŸ§  Quantization Policy

| Aspect      | Requirement                                    |
| ----------- | ---------------------------------------------- |
| Format      | **Q4_K_M preferred** (best quality/VRAM ratio) |
| Requirement | **Mandatory** for local inference              |
| Philosophy  | Optimization, not limitation                   |
| FP16 Models | âŒ Not supported on Railway                    |

**Recommended Models:**

- DeepSeek-R1-Distill 7B Q4
- Llama 3.1 8B Q4_K_M
- Mistral 7B Q4_K_M

---

## ğŸ”Œ Pluggable Inference Providers

The backend is designed for inference source flexibility:

| Provider           | Status     | Use Case                   |
| ------------------ | ---------- | -------------------------- |
| Local GPU (Ollama) | âœ… Current | Development, personal use  |
| OpenAI API         | ğŸ”® Future  | Fallback, premium features |
| Anthropic Claude   | ğŸ”® Future  | Enhanced reasoning         |
| Groq               | ğŸ”® Future  | Ultra-fast inference       |
| RunPod / Lambda    | ğŸ”® Future  | Dedicated GPU cloud        |

> Switching providers requires **zero frontend changes**.

---

## ğŸ“ Project Structure

```
Aris2/
â”œâ”€â”€ frontend/                  # Flutter application
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ app/              # App configuration
â”‚   â”‚   â”œâ”€â”€ core/             # Shared utilities & services
â”‚   â”‚   â””â”€â”€ features/
â”‚   â”‚       â”œâ”€â”€ auth/         # Authentication screens
â”‚   â”‚       â”œâ”€â”€ chat/         # Chat interface & logic
â”‚   â”‚       â”œâ”€â”€ media/        # Media handling
â”‚   â”‚       â”œâ”€â”€ projects/     # Project management
â”‚   â”‚       â”œâ”€â”€ settings/     # User preferences
â”‚   â”‚       â””â”€â”€ vault/        # Personal Space (secure)
â”‚   â”œâ”€â”€ assets/               # Images, icons, animations
â”‚   â””â”€â”€ pubspec.yaml
â”‚
â”œâ”€â”€ backend/                   # FastAPI backend (Railway)
â”‚   â””â”€â”€ (TBD)
â”‚
â””â”€â”€ inference/                 # Local inference setup
    â””â”€â”€ (TBD)
```

---

## ğŸš€ Getting Started

### Prerequisites

| Component     | Requirement         |
| ------------- | ------------------- |
| Flutter       | 3.10+               |
| Dart          | 3.10+               |
| Node.js       | 18+ (for backend)   |
| Python        | 3.10+ (for backend) |
| Ollama        | Latest              |
| NVIDIA Driver | Latest              |

### Frontend Setup

```bash
cd frontend
flutter pub get
flutter run
```

### Backend Setup (Railway)

```bash
# Coming soon...
```

### Local Inference Setup

```bash
# Install Ollama
# https://ollama.ai/download

# Pull quantized model
ollama pull deepseek-r1:7b-q4_K_M

# Start Ollama server
ollama serve
```

---

## âœ… Success Criteria

| Criterion       | Target                        |
| --------------- | ----------------------------- |
| Responsiveness  | ChatGPT-like feel             |
| Stability       | Works on limited hardware     |
| Cloud Costs     | Minimal (Railway free tier)   |
| AI on Railway   | âŒ None                       |
| Separation      | Orchestration â‰  Computation   |
| Maintainability | Easy to deploy, debug, extend |

---

## ğŸ›£ï¸ Roadmap

- [ ] Phase 1: Core chat functionality
- [ ] Phase 2: Voice input integration
- [ ] Phase 3: Personal Space implementation
- [ ] Phase 4: Daily updates & notifications
- [ ] Phase 5: Multi-provider inference support

---

## ğŸ“„ License

This project is proprietary. All rights reserved.

---

<p align="center">
  <em>Built with â¤ï¸ for efficient AI interaction</em>
</p>
